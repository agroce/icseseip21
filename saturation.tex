\section{Initial Contact and the Problem of Saturation}

Chaincode labs (\url{https://chaincode.com/}) is a private R\&D center based in Manhattan that exists solely to support and develop Bitcoin.  In March of 2021, Adam Jonas, the head of special projects at Chaincode, contacted the first author to discuss determining a strategy to improve the fuzzing of Bitcoin Core.  In particular, at the time, it seemed that the fuzzing was ``stuck'': neither code coverage nor found bugs were increasing with additional fuzzing time.  After some discussion, an 80 hour effort was determined as a reasonable scope for an external, research-oriented, look at the fuzzing effort.  Before that effort, conducted over the summer of 2021, began, the problem of saturation resolved itself.  Nonetheless, the issue that drove the initial desire for a researcher investigation is well worth examining.  Moreover, understanding why Bitcoin Core fuzzing was, temporarily but not fundamentally, saturated, may be useful to help other fuzzing campaigns avoid the same false saturation problem.

Saturation, as defined in the blog post (\url{https://blog.regehr.org/archives/1796}) that brought Chaincode labs to the first author, is when ``We apply a fuzzer to some non-trivial system... initially it finds a lot of bugs... [but] the number of new bugs found by the fuzzer drops off, eventually approaching zero.''  That is, at first a fuzzer applied to a system will tend to continuously, sometimes impressively, increase both coverage and discovery of previously-unknown bugs.  But, at some point, these bugs are known (and often fixed) and the fuzzer stops producing new bugs.  Code and behavioral coverage seems to be \emph{saturated}.

The underlying reason for saturation is that any fuzzer (or other test generator) explores a space of generated tests according to some, perhaps very complex, probability distribution.  Some bugs lie in the high-probabiliity portion of this space, and other bugs like in very low probability (or in some cases, zero probability) parts of the space.  Unsurprisingly, eventually the high probability space is well-explored, and the remaining bugs are found only very infrequently, if ever.  The underlying empirical facts are cruel, as noted by B\"{o}hme and Falk:  ``[W]ith twice the machines, we can find \emph{all known} bugs in half the time. Yet, finding linearly \emph{more} bugs in the same time requires exponentially more machines'' \cite{fuzzexp}.

Chaincode labs saw that code coverage and bugs were not increasing in their fuzzer runs, and wanted to break out of the saturation trap.  The blog post suggested several methods for doing just that, and this paper explores some of them.  Note that even though the fuzzing was not saturated, the methods for escaping saturation are also useful things to try in any fuzzing effort where finding as many bugs as possible is actually important.

\subsection{We Hold the World Ransom For... ONE MILLION FUZZER ITERATIONS}

